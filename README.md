# Machine-Learning-
This folder contains a set of typical machine learning exercises along with their solutions implemented in Jupyter Notebooks. The projects cover various ML concepts including supervised and unsupervised learning, data preprocessing, feature engineering, model training, and evaluation using standard metrics. The notebooks demonstrate step-by-step implementations of algorithms and provide hands-on experience for understanding core machine learning techniques.
Questions:
Q1. Minimize the given function f(x) = 2x2-3x3+x4+1 using the gradient descent algorithm.
a. Plot the graph of f(x) and obtain the global minima graphically.
b. Obtain the global minima using gradient and note down the maximum value of epoch at which the algorithm converges.
c. Repeat part (b) for several values of learning rate and plot a graph of learning
rate (x-axis) vs max-convergence-epoch (y-axis).

Q2. Implement the linear regression on the given training dataset (n=number of training examples). Use gradient descent to optimize the loss function. Calculate the residual
standard error (RSS) using the test dataset. Plot a graph of n vs RSS for different size of training dataset as 0.1*n, 0.2*n, ...... , 0.9*n, n.

Q3. Generate the synthetic dataset of n instances (input n from user) for sine function withGaussian noise of mean zero and variance of 0.3. Implement the polynomial regression on the training dataset (n=number of training examples). Use gradient descent to optimize the loss function. Fit the model for degrees of polynomial m (input m from user). Calculate the residual standard error (RSS) using the test dataset. Plot a graph of n vs RSS for different size of training dataset as 0.1*n, 0.2*n, ...... , 0.9*n, n. Perform the experiments for values of m = 1 to 10.

Q4. Implement the logistic regression on the given training dataset (n=number of training examples). Use gradient descent to optimize the loss function. Calculate the precision,recall and F-Score using the test dataset. Plot a graph of n vs F-score for different size
of training dataset as 0.1*n, 0.2*n, ...... , 0.9*n, n.

Q5. Implement the k Nearest Neighbour Algorithm on the given dataset. Predict the class label for the given test samples.

Q6. Implement the Bernoulli Na誰ve Bayes Algorithm on the given dataset. Use Add-1 Laplace smoothing. Predict the class label for the given test samples.

Q7. Implement the Multinomial Na誰ve Bayes Algorithm on the given dataset. Use Add-1 Laplace smoothing. Predict the class label for the given test samples.

Q8. Implement Na誰ve Bayes and Logistic Regression on the given dataset. Compare the performances of each classifier using confusion matrix and classification reports.

Q9. Implement Adaboost algorithm using sklearn library. Use different classifiers (e.g. decision tree, logistic regression, na誰ve bayes) for base classifiers. Compare the
performances of all the Adaboost models obtained.

Q10. Implement several classification methods using sklearn library. Split the given dataset into train and test set. Evaluate each classifier on same test set and compare the Performance on the basis of Prescion, Recall and F-score.
performance on the basis of Precision, Recall and F-Score.
structure propely
